{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Client Report - Project 4\"\n",
        "subtitle: \"Course DS 250\"\n",
        "author: \"Colin Israelsen\"\n",
        "format:\n",
        "  html:\n",
        "    self-contained: true\n",
        "    page-layout: full\n",
        "    title-block-banner: true\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    toc-location: body\n",
        "    number-sections: false\n",
        "    html-math-method: katex\n",
        "    code-fold: true\n",
        "    code-summary: \"Show the code\"\n",
        "    code-overflow: wrap\n",
        "    code-copy: hover\n",
        "    code-tools:\n",
        "        source: false\n",
        "        toggle: true\n",
        "        caption: See code\n",
        "execute: \n",
        "  warning: false\n",
        "    \n",
        "---"
      ],
      "id": "fef4027e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "id": "73eb605b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# read in file\n",
        "df = pd.read_csv('dwellings_ml.txt')"
      ],
      "id": "462ae310",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Highlight the Questions and Tasks__\n",
        "\n",
        "## QUESTION|TASK 1\n",
        "\n",
        "__Create 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.__\n",
        "\n",
        "_In the chart down below, outliers are severely affecting and shifting the data. Although, one thing that I noticed in this chart is that although there are many outliers for before and after 1980, there is a significant increase in sales price after the year 1980. However, after 1980 has the highest outlier close to $10M._\n"
      ],
      "id": "f1dee194"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# convert before1980 to a categorical variable\n",
        "df['before1980'] = df['before1980'].astype('category')\n",
        "\n",
        "# shart for sales price comparison for before1980 status\n",
        "chart1 = px.box(df, x='before1980', \n",
        "y='sprice', \n",
        "color='before1980', \n",
        "title='Sales Price by Before1980 Status')\n",
        "\n",
        "# change y axis range\n",
        "chart1.update_yaxes(range=[0, 10000000])\n",
        "\n",
        "# change axis titles\n",
        "chart1.update_layout(\n",
        "    xaxis_title='Before1980 Status',\n",
        "    yaxis_title='Sales Price')\n",
        "\n",
        "chart1.show()"
      ],
      "id": "c545d037",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_The chart below shows the relationship between the number homes built each year as time goes on before and after 1980. I noticed that before 1980 the number of houses built was never consistent. It seemed to fluctuate a lot goin up and down on how many houses were built within the year. After 1980 the number of houses built dropped around the 90s and then consistently increased going into the 2000s higher than how many houses were built before the 1980s._\n"
      ],
      "id": "458af8e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# chart for number of homes built before and after 1980\n",
        "chart2 = px.histogram(df, x='yrbuilt', \n",
        "color='before1980', \n",
        "title='Year Built Distribution by Before1980 Status')\n",
        "\n",
        "#change axis titles\n",
        "chart2.update_layout(\n",
        "  xaxis_title='Year Built',\n",
        "  yaxis_title='Number of Homes Built'\n",
        ")\n",
        "\n",
        "# make outside line of histogram bars black\n",
        "chart2.update_traces(marker_line_color='black', marker_line_width=2)\n",
        "\n",
        "chart2.show()"
      ],
      "id": "73e4bd5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Below is a chart that shows the relationship of how many bedrooms a house had depending on the sales price of the home. Most of the houses either before or after 1980 had outliers that affect and shift the data. Although, the houses built after 1980 had not only more bedrooms, but they had more outliers in sales price. This could have been caused by the great recession of 2008._\n"
      ],
      "id": "deb6b98a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# chart for number of bedrooms before and after 1980\n",
        "chart3 = px.box(df, x='numbdrm', \n",
        "y='sprice', \n",
        "color='before1980', \n",
        "title='Number of Bedrooms vs. Sale Price by Before1980 Status')\n",
        "\n",
        "# change axis titles\n",
        "chart3.update_layout(\n",
        "  xaxis_title='Number of Bedrooms', \n",
        "  yaxis_title='Sales Price'\n",
        ")\n",
        "\n",
        "# change the interval scale of the x axis\n",
        "chart3.update_xaxes(dtick=1)\n",
        "\n",
        "chart3.show()"
      ],
      "id": "5a737e72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QUESTION|TASK 2\n",
        "\n",
        "__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.__\n",
        "\n",
        "_I did a model of Logistic Regression and a model for Random Forest Classifier. Both models are very accurate and were not off by that much accuracy from each other. Although, the Random Forest Classifier model had a perfect accuracy so that one would be the model to choose._\n"
      ],
      "id": "6956657d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# split the data\n",
        "df_drop_parcel = df.drop(['before1980', 'parcel'], axis=1)\n",
        "df_no_drop_parcel = df['before1980']\n",
        "\n",
        "# Splitting the dataset into training and testing sets again\n",
        "df_drop_parcel_train, df_drop_parcel_test, df_no_drop_parcel_train, df_no_drop_parcel_test = train_test_split(df_drop_parcel, df_no_drop_parcel, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizing the features again\n",
        "scaler = StandardScaler()\n",
        "df_drop_parcel_train_scaled = scaler.fit_transform(df_drop_parcel_train)\n",
        "df_drop_parcel_test_scaled = scaler.transform(df_drop_parcel_test)\n",
        "\n",
        "# Logistic Regression Model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(df_drop_parcel_train_scaled, df_no_drop_parcel_train)\n",
        "df_no_drop_parcel_pred_log_reg = log_reg.predict(df_drop_parcel_test_scaled)\n",
        "accuracy_log_reg = accuracy_score(df_no_drop_parcel_test, df_no_drop_parcel_pred_log_reg)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(random_state=42) # Side Note: AI was used to come up with and format lines 147-150 of this code for this question\n",
        "rf_clf.fit(df_drop_parcel_train_scaled, df_no_drop_parcel_train)\n",
        "df_no_drop_parcel_pred_rf_clf = rf_clf.predict(df_drop_parcel_test_scaled)\n",
        "accuracy_rf_clf = accuracy_score(df_no_drop_parcel_test, df_no_drop_parcel_pred_rf_clf)\n",
        "\n",
        "print('Logistic Regression Accuracy:', accuracy_log_reg)\n",
        "print('Random Forest Classifier Accuracy:', accuracy_rf_clf)"
      ],
      "id": "b2d970a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QUESTION|TASK 3\n",
        "\n",
        "__Justify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.__\n"
      ],
      "id": "971117da"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# get feature importance\n",
        "feature_importances = rf_clf.feature_importances_\n",
        "\n",
        "# create a feature dataframe\n",
        "features_df = pd.DataFrame({'Feature': df_drop_parcel.columns, 'Importance': feature_importances})\n",
        "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# remove yrbuilt column\n",
        "features_df = features_df[features_df['Feature'] != 'yrbuilt']"
      ],
      "id": "abd7dc4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_While making this chart the column 'yrbuilt' was an extreme outlier compared to the rest of the features for a house so that column was removed so there would be a more accurate comparison for the rest of the features. The top 3 features for a house are the number of stories, the number of bathrooms, and the quality of the home. After those 3 most of the data is around the same or not as important for the ratio of the chart. This means that houses that have more features better for the ones of more importance are likely to sell better and faster._\n"
      ],
      "id": "7a63ac6b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# make a chart\n",
        "chart4 = px.bar(features_df, x='Importance', y='Feature', title='Feature Importance in Random Forest Classifier', orientation='h')\n",
        "chart4.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "\n",
        "# change axis titles\n",
        "chart4.update_layout(\n",
        "  xaxis_title='Importance', \n",
        "  yaxis_title='Feature'\n",
        ")\n",
        "\n",
        "chart4.show()"
      ],
      "id": "e46ce4b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QUESTION|TASK 4\n",
        "\n",
        "__Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.__\n",
        "\n",
        "_type your results and analysis here_\n"
      ],
      "id": "c4475dee"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}